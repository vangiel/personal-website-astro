---
title: "Tutorial: First Step in a RAG pipeline, Data Ingestion (Part 3) - Data embedding and data storing."
pubDate: "Oct 02 2024"
heroImage: "@/images/blog/Tutorials/2_Data_ingestion_RAG/frontmatter.png"
imageAlt: "Frontmatter of the page which consists of a scheme of the indexing part of a RAG  pipeline."
tags: ["Tutorials", "Web Development", "AI"]
slug: "tutorials/data-ingestion-part3"
---

import { Image } from "astro:assets";

This final part of the tutorial will cover the final steps in the data ingestion phase of a RAG pipeline: data embedding and data storing. These steps are highlighted in red within the pipeline diagram.

import dataStoringImg from "@/images/blog/Tutorials/2_Data_ingestion_RAG/dataStoring.png";

<Image
	src={dataStoringImg}
	alt="Scheme of data ingesting step in RAG workflow highlighting data embedding and data storing steps."
/>

As mentioned earlier, we'll be using a model from [Cloudflare Workers AI](https://developers.cloudflare.com/workers-ai/models/) to generate vector representations from the text data. These vectors will be stored in the Qdrant database, while the corresponding text will be saved in the CloudFlare D1 database we created in the previous step. I've developed a TypeScript script to handle this process; the code explanation will be provided in the next section.

## Script for Embedding and Storing the Data

We'll begin by creating an `add-notes.ts` file to write the code. This script will process the data stored in the JSON file generated in the first part of the tutorial, create vector embeddings, and store the data in the databases established in the previous steps.

We'll execute this script using `tsx`, a Node.js enhancement designed for directly running TypeScript:

```bash
tsx --env-file=.env add-notes.ts
```

Please note that we must specify the path to our `.env` file if we're storing global variables there, such as the Qdrant API key as discussed earlier.

### Imports and Global Variables

We'll begin by importing the `fs` (file system) package from Node.js to read the JSON file containing our data, along with the utility class created in the previous step for managing the Qdrant database.

```ts
// add-notes.ts
import fs from "fs";
import { type Point, QdrantDatabase } from "../qdrant";
```

Next, we'll declare several variables that will be used to call the APIs of the CloudFlare D1 database and CloudFlare AI. Remember that we'll need to employ an embedding model from CloudFlare AI to generate vectors from the text stored in the JSON file.

```ts
// add-notes.ts
// Constant for calling D1 API
const ACCOUNT_ID: string = "xxxxxxxxxxxxxxxx";
const DATABASE_ID: string = "xxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx";
const D1_QUERY_URL: string = `https://api.cloudflare.com/client/v4/accounts/${ACCOUNT_ID}/d1/database/${DATABASE_ID}/query`;

// Constant for calling AI API
const MODEL_NAME: string = "@cf/baai/bge-base-en-v1.5";
const AI_RUN_URL: string = `https://api.cloudflare.com/client/v4/accounts/${ACCOUNT_ID}/ai/run/${MODEL_NAME}`;
```

To find your CloudFlare account ID, navigate to the **Workers & Pages/Overview** section. It will be displayed on the right side of the screen under **Account details**:

import IDLocationImg from "@/images/blog/Tutorials/2_Data_ingestion_RAG/Pasted image 20241002184332.png";

<Image
	style="margin-inline:auto;"
	src={IDLocationImg}
	alt="Location of CloudFlare account ID on the CloudFlare dashboard."
/>

The database ID can be found in your `wrangler.toml` file, which you created in a previous step of this tutorial. Finally, we'll use the `"@cf/baai/bge-base-en-v1.5"` model to generate our vector embeddings. Remember to add the following lines to your `wrangler.toml` file to enable the binding with CloudFlare AI:

```toml
// wrangler.toml
[ai]
binding = "AI"
```

### The Main Function

Now, let's create the main function that will handle all the processing. The initial steps involve loading the data from the JSON file and initializing the Qdrant class. Then, we'll create a for loop to iterate through each note in the JSON file:

```ts
// add-notes.ts
async function main(filePath: string) {
	const notes: String[] = JSON.parse(fs.readFileSync(filePath, "utf-8"));
	const Qdrant = new QdrantDatabase("info", 768);

	let points: Point[] = [];

	for (const note of notes) {
		...
	}

	await Qdrant.addPoints(points);
	return 0;
}
```

We'll store the vectors in the `points` array and, at the end of the loop, store them in the Qdrant database.

:::note
You can name the collection whatever you prefer. In this example, I've named it "info." Also, ensure that the vector size is **$768$**, as this matches the size generated by the embedding model.
:::

### Data Processing

This is the complete code within the for loop, which processes each note individually and stores it. First, we fetch the CloudFlare D1 dataset to insert the text into a row within our `notes` table. Then, we store the "results" field of the response in a variable called `record`. **This variable contains the ID of the row where the text was inserted, which will be crucial for later use.**

```ts
// add-notes.ts
	for (const note of notes) {
		console.log("Storing note", note);
		// Store the note in the Cloudflare D1 database using the API
		let d1Response = await fetch(D1_QUERY_URL, {
			method: "POST",
			headers: {
				"Authorization": "Bearer " + process.env.CLOUDFLARE_API_TOKEN,
				"Content-Type": "application/json",
			},
			body: JSON.stringify({
				params: [note],
				sql: "INSERT INTO notes (text) VALUES (?) RETURNING *",
			}),
		});
		d1Response = await d1Response.json();
		// @ts-ignore
		const record = d1Response.result[0].results.length ? d1Response.result[0].results[0] : null;

		if (!record) {
			console.log("Failed to create note", note);
			return;
		}
		...
	}

```

:::note
Note that we're retrieving the CloudFlare API token created in the previous part of this tutorial from the `.env` file.
:::

The next step involves creating the vector embedding for each note. We achieve this by calling the CloudFlare AI API. The generated vector will be stored within the response object, specifically in the `result.data` field. We'll store this vector in the `values` variable. Once obtained, the vector is added to the `points` list, along with its corresponding ID retrieved from the CloudFlare D1 database insertion.

```ts
// add-notes.ts
	for (const note of notes) {
		...
		// Create the vector for that note using the AI model from Cloudflare. Acessed via API
		let aiResponse = await fetch(AI_RUN_URL, {
			method: "POST",
			headers: {
				"Authorization": "Bearer " + process.env.CLOUDFLARE_API_TOKEN,
				"Content-Type": "application/json",
			},
			body: JSON.stringify({
				text: note,
			}),
		});
		aiResponse = await aiResponse.json();
		// @ts-ignore
		const values = aiResponse.result.data[0];

		if (!values) {
			console.log("Failed to generate vector embedding", note);
			return;
		}

		// Store vector in vectorize Qdrant database with the same id
		const { id } = record;
		points.push({
			id: id,
			vector: values,
		});
	}
```

:::danger[important]
It's crucial to store the vector alongside its corresponding ID. This ID serves as the unique identifier linking the text and its associated vector.
:::

### Calling the Main Function

Finally, at the end of the script, we call the main function, passing the path to the JSON file to be processed:

```ts
// add-notes.ts
main("./notes.json")
	.then((code) => {
		console.log("All notes stored succesfully.");
		process.exit(code);
	})
	.catch((err) => {
		console.error(err);
		process.exit(1);
	});
```

## Testing the Setup

As a final step, if you want to verify that everything is working correctly without errors, you can check if the data has been stored using the user interfaces of Qdrant and CloudFlare D1.

To start, for the Qdrant database, navigate to your cluster dashboard. If you've carefully followed all the steps in this tutorial, you should now see something similar to this:

import QdrantImg from "@/images/blog/Tutorials/2_Data_ingestion_RAG/Pasted image 20241003093345.png";

<Image src={QdrantImg} alt="Location of CloudFlare account ID on the CloudFlare dashboard." />

Each of these points represents the vector for the corresponding note. The notes themselves are stored in plain text format within the CloudFlare D1 database. If you visit the D1 dashboard in your CloudFlare account, you can access the `notes` table and view the entries:

import CludFlareImg from "@/images/blog/Tutorials/2_Data_ingestion_RAG/Pasted image 20241003093215.png";

<Image src={CludFlareImg} alt="Location of CloudFlare account ID on the CloudFlare dashboard." />

:::tip
You can manually modify the rows within the CloudFlare D1 dataset. Additionally, you can perform similarity searches directly on the Qdrant dashboard for testing purposes.
:::

## Conclusions

In this tutorial, we've explored the first of two steps in a RAG pipeline: data ingestion. This process involves loading data from various sources, splitting the text into semantic chunks, and storing them for their posterior processing. Remember that the code we saw in this tutorial is publicly available on [GitHub.](https://github.com/vangiel/Tutorials/tree/main/Chabot-in-AstroJS)

As you're likely aware, the second part of the RAG pipeline focuses on information retrieval. This involves retrieving stored information to provide the LLM with more context for answering user queries. If you're interested in learning how to create a fully functional chatbot using a RAG pipeline, I'll be publishing a tutorial on this topic soon.
